# RAG (Retrieval-Augmented Generation) for Knowledge Base
# Answers questions using video transcripts

import logging
from typing import Optional

from openai import AsyncOpenAI

from config.settings import OPENAI_API_KEY
from knowledge_base.db_manager import search_chunks, get_knowledge_stats

logger = logging.getLogger(__name__)


class KnowledgeRAG:
    """RAG system for answering questions from video knowledge base."""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
        self.embedding_model = "text-embedding-3-small"
        self.chat_model = "gpt-4o-mini"
        
        self.system_prompt = """–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è —Ñ—Ä–∞–Ω—á–∞–π–∑–∏ –±–∞—Ä–±–µ—Ä—à–æ–ø–æ–≤ BORODACH. 
–£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –∏–∑ –æ–±—É—á–∞—é—â–∏—Ö –≤–∏–¥–µ–æ.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞:
1. –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –∏—Å–ø–æ–ª—å–∑—É—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤–∏–¥–µ–æ
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –µ—Å—Ç—å –≤ –≤–∏–¥–µ–æ ‚Äî —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ —É—Ä–æ–∫–∞
3. –û—Ç–≤–µ—á–∞—Ç—å –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É
4. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞ ‚Äî —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∑–∞—Ç—å –æ–± —ç—Ç–æ–º

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:
- –ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å
- –°—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–¥–µ–æ: "üìπ –ü–æ–¥—Ä–æ–±–Ω–µ–µ: {–Ω–∞–∑–≤–∞–Ω–∏–µ —É—Ä–æ–∫–∞}"

–ï—Å–ª–∏ –Ω–µ –Ω–∞—à—ë–ª –æ—Ç–≤–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ:
"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–≤—è–∑–∞—Ç—å—Å—è —Å –æ—Ñ–∏—Å–æ–º —á–µ—Ä–µ–∑ —Ä–∞–∑–¥–µ–ª '–ü–æ–ª–µ–∑–Ω–æ–µ'."
"""
    
    async def create_query_embedding(self, query: str) -> Optional[list[float]]:
        """Create embedding for search query."""
        if not self.client:
            logger.error("[RAG] OpenAI client not configured")
            return None
        
        try:
            response = await self.client.embeddings.create(
                model=self.embedding_model,
                input=query
            )
            return response.data[0].embedding
        except Exception as e:
            logger.error(f"[RAG] Error creating embedding: {e}")
            return None
    
    async def search(self, query: str, limit: int = 3) -> list[dict]:
        """Search for relevant chunks in knowledge base."""
        embedding = await self.create_query_embedding(query)
        if not embedding:
            return []
        
        results = await search_chunks(embedding, limit=limit)
        logger.info(f"[RAG] Found {len(results)} relevant chunks for query: {query[:50]}...")
        return results
    
    def format_context(self, chunks: list[dict]) -> str:
        """Format search results as context for GPT."""
        if not chunks:
            return "–ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω."
        
        context_parts = []
        for i, chunk in enumerate(chunks, 1):
            context_parts.append(
                f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {i}]\n"
                f"–£—Ä–æ–∫: {chunk.get('lesson_title', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}\n"
                f"–¢–µ–∫—Å—Ç: {chunk.get('text', '')}\n"
            )
        
        return "\n---\n".join(context_parts)
    
    async def answer(self, question: str) -> str:
        """
        Answer a question using RAG.
        Returns formatted answer with video references.
        """
        if not self.client:
            return "‚ö†Ô∏è –°–∏—Å—Ç–µ–º–∞ –æ—Ç–≤–µ—Ç–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        
        # Check if knowledge base has data
        stats = await get_knowledge_stats()
        if stats["embedded_count"] == 0:
            return "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –ø–æ–∫–∞ –ø—É—Å—Ç–∞. –°–∫–æ—Ä–æ –∑–¥–µ—Å—å –ø–æ—è–≤—è—Ç—Å—è –æ–±—É—á–∞—é—â–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã!"
        
        # Search for relevant chunks
        chunks = await self.search(question, limit=3)
        
        if not chunks:
            return (
                "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ –Ω–∞—à—ë–ª –ø–æ–¥—Ö–æ–¥—è—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.\n\n"
                "üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –æ—Ñ–∏—Å "
                "—á–µ—Ä–µ–∑ —Ä–∞–∑–¥–µ–ª ¬´üìö –ü–æ–ª–µ–∑–Ω–æ–µ¬ª."
            )
        
        # Format context
        context = self.format_context(chunks)
        
        try:
            logger.info(f"[RAG] Generating answer for: {question[:50]}...")
            
            response = await self.client.chat.completions.create(
                model=self.chat_model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤–∏–¥–µ–æ:\n\n{context}\n\n–í–æ–ø—Ä–æ—Å: {question}"}
                ],
                temperature=0.3,
                max_tokens=500,
                timeout=15.0
            )
            
            answer = response.choices[0].message.content
            logger.info(f"[RAG] Answer generated (tokens: {response.usage.total_tokens})")
            
            return answer
            
        except Exception as e:
            logger.error(f"[RAG] Error generating answer: {e}")
            return "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
    
    async def is_knowledge_question(self, text: str) -> bool:
        """
        Check if the text is a question that should be answered from knowledge base.
        Returns True if it looks like a question about franchise operations.
        """
        # Keywords that suggest a knowledge question
        knowledge_keywords = [
            "–∫–∞–∫", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º", "–∫–æ–≥–¥–∞", "–≥–¥–µ", "—á—Ç–æ —Ç–∞–∫–æ–µ",
            "—Å–∫–æ–ª—å–∫–æ", "–∫–∞–∫–æ–π", "–∫–∞–∫–∞—è", "–∫–∞–∫–∏–µ",
            "—Ä–∞—Å—Å–∫–∞–∂–∏", "–æ–±—ä—è—Å–Ω–∏", "–ø–æ–¥—Å–∫–∞–∂–∏", "–ø–æ–º–æ–≥–∏",
            "–¥–µ–ª–∞—Ç—å", "—Ä–∞–±–æ—Ç–∞—Ç—å", "–æ—Ñ–æ—Ä–º–∏—Ç—å", "–ø–æ–ª—É—á–∏—Ç—å",
            "–∫–ª–∏–µ–Ω—Ç", "—Å–æ—Ç—Ä—É–¥–Ω–∏–∫", "–∫–∞—Å—Å–∞", "–≤—ã—Ä—É—á–∫–∞", "–∑–∞—Ä–ø–ª–∞—Ç–∞",
            "–æ–±—É—á–µ–Ω–∏–µ", "—Å—Ç–∞–Ω–¥–∞—Ä—Ç", "–ø—Ä–æ—Ü–µ–¥—É—Ä–∞", "—Ä–µ–≥–ª–∞–º–µ–Ω—Ç",
            "yclients", "–±–∏—Ç—Ä–∏–∫—Å", "bitrix",
        ]
        
        text_lower = text.lower()
        
        # Check for question marks or keywords
        if "?" in text:
            return True
        
        for keyword in knowledge_keywords:
            if keyword in text_lower:
                return True
        
        return False


# Singleton instance
knowledge_rag = KnowledgeRAG()

